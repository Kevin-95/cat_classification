{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data7983\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained\r\n"
     ]
    }
   ],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip data/data7983/cat_12.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wget https://paddle-imagenet-models-name.bj.bcebos.com/ResNet101_vd_pretrained.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!tar -xvf ResNet101_vd_pretrained.tar -C work/pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "import reader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##生成test.txt\n",
    "#filepath='cat_12/cat_12_test'\n",
    "#pathlist=os.listdir(filepath)\n",
    "#print(pathlist)\n",
    "#with open('cat_12/test_list.txt','w+') as f:\n",
    "    #for file_name in pathlist:\n",
    "        #f.write(file_name+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    180\n",
      "9     180\n",
      "7     180\n",
      "5     180\n",
      "3     180\n",
      "1     180\n",
      "10    180\n",
      "8     180\n",
      "6     180\n",
      "4     180\n",
      "2     180\n",
      "0     180\n",
      "Name: 1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_table('cat_12/train_list.txt',header=None)\n",
    "print(a[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##处理数据集，将原有训练集按二八比例分割\n",
    "with open('cat_12/train_list.txt','r') as f:\n",
    "    with open('cat_12/train_split_list.txt','w+') as train:\n",
    "        lines=f.readlines()\n",
    "    with open('cat_12/train_split_list.txt','w+') as train:\n",
    "        for i in range(0,2160,180):\n",
    "            for line in lines[i:i+135]:\n",
    "                train.write(line)\n",
    "    with open('cat_12/val_split_list.txt','w+') as val:\n",
    "        for i in range(0,2160,180):\n",
    "            for line in lines[i+135:i+180]:\n",
    "                val.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    135\n",
      "10    135\n",
      "9     135\n",
      "8     135\n",
      "7     135\n",
      "6     135\n",
      "5     135\n",
      "4     135\n",
      "3     135\n",
      "2     135\n",
      "1     135\n",
      "0     135\n",
      "Name: 1, dtype: int64\n",
      "11    45\n",
      "10    45\n",
      "9     45\n",
      "8     45\n",
      "7     45\n",
      "6     45\n",
      "5     45\n",
      "4     45\n",
      "3     45\n",
      "2     45\n",
      "1     45\n",
      "0     45\n",
      "Name: 1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_table('cat_12/train_split_list.txt',header=None)\n",
    "print(train[1].value_counts())\n",
    "val=pd.read_table('cat_12/val_split_list.txt',header=None)\n",
    "print(val[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取猫数据\n",
    "train_reader = paddle.batch(reader.train(), batch_size=16)\n",
    "test_reader = paddle.batch(reader.val(), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义残差网络\n",
    "def resnet(input):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "            \n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 23, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=32, filter_size=3, stride=2, act='relu', name='conv1_1')\n",
    "    conv = conv_bn_layer(input=conv, num_filters=32, filter_size=3, stride=1, act='relu', name='conv1_2')\n",
    "    conv = conv_bn_layer(input=conv, num_filters=64, filter_size=3, stride=1, act='relu', name='conv1_3')\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            if block == 2:\n",
    "                if i == 0:\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\n",
    "                else:\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\n",
    "            else:\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    return pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义输入层\n",
    "image=fluid.layers.data(name='image',shape=[3,224,224],dtype='float32')\n",
    "label=fluid.layers.data(name='label',shape=[1],dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##停止梯度下降\n",
    "pool=resnet(image)\n",
    "pool.stop_gradient=True\n",
    "\n",
    "##创建主程序\n",
    "base_model_program=fluid.default_main_program().clone()\n",
    "model=fluid.layers.fc(input=pool,size=12,act='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##定义损失函数和准确率函数\n",
    "cost=fluid.layers.cross_entropy(input=model,label=label)\n",
    "avg_cost=fluid.layers.mean(cost)\n",
    "acc=fluid.layers.accuracy(input=model,label=label)\n",
    "\n",
    "##定义优化方法\n",
    "optimizer=fluid.optimizer.AdamOptimizer(learning_rate=5e-4)\n",
    "opts=optimizer.minimize(avg_cost)\n",
    "\n",
    "##定义训练场所\n",
    "use_gpu=True\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "exe=fluid.Executor(place)\n",
    "\n",
    "##进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##预训练模型路径\n",
    "src_pretrain_model_path='work/pretrained/ResNet101_vd_pretrained'\n",
    "\n",
    "##判断模型文件是否存在\n",
    "def if_exit(var):\n",
    "    path=os.path.join(src_pretrain_model_path,var.name)\n",
    "    exist=os.path.exists(path)\n",
    "    return exist\n",
    "\n",
    "##加载模型文件，且只加载存在模型的模型文件\n",
    "fluid.io.load_vars(executor=exe,dirname=src_pretrain_model_path,predicate=if_exit,main_program=base_model_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "memory_optimize is deprecated. Use CompiledProgram and Executor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.45054, Accuracy:0.06250\n",
      "Pass:0, Batch:50, Cost:2.19897, Accuracy:0.37500\n",
      "Pass:0, Batch:100, Cost:2.01380, Accuracy:0.37500\n",
      "Pass:1, Batch:0, Cost:2.08835, Accuracy:0.31250\n",
      "Pass:1, Batch:50, Cost:1.74305, Accuracy:0.43750\n",
      "Pass:1, Batch:100, Cost:1.58389, Accuracy:0.62500\n",
      "Pass:2, Batch:0, Cost:1.70267, Accuracy:0.56250\n",
      "Pass:2, Batch:50, Cost:1.80711, Accuracy:0.43750\n",
      "Pass:2, Batch:100, Cost:1.72208, Accuracy:0.37500\n",
      "Pass:3, Batch:0, Cost:1.28303, Accuracy:0.81250\n",
      "Pass:3, Batch:50, Cost:1.56882, Accuracy:0.56250\n",
      "Pass:3, Batch:100, Cost:1.69748, Accuracy:0.37500\n",
      "Pass:4, Batch:0, Cost:1.57360, Accuracy:0.62500\n",
      "Pass:4, Batch:50, Cost:1.65409, Accuracy:0.50000\n",
      "Pass:4, Batch:100, Cost:1.25496, Accuracy:0.68750\n",
      "Pass:5, Batch:0, Cost:1.26319, Accuracy:0.56250\n",
      "Pass:5, Batch:50, Cost:1.03318, Accuracy:0.75000\n",
      "Pass:5, Batch:100, Cost:1.34811, Accuracy:0.56250\n",
      "Pass:6, Batch:0, Cost:1.09125, Accuracy:0.68750\n",
      "Pass:6, Batch:50, Cost:0.83072, Accuracy:0.68750\n",
      "Pass:6, Batch:100, Cost:1.64845, Accuracy:0.43750\n",
      "Pass:7, Batch:0, Cost:1.05599, Accuracy:0.75000\n",
      "Pass:7, Batch:50, Cost:1.05095, Accuracy:0.75000\n",
      "Pass:7, Batch:100, Cost:1.30901, Accuracy:0.50000\n",
      "Pass:8, Batch:0, Cost:1.18520, Accuracy:0.68750\n",
      "Pass:8, Batch:50, Cost:1.42941, Accuracy:0.43750\n",
      "Pass:8, Batch:100, Cost:1.19123, Accuracy:0.81250\n",
      "Pass:9, Batch:0, Cost:0.96552, Accuracy:0.62500\n",
      "Pass:9, Batch:50, Cost:0.97389, Accuracy:0.75000\n",
      "Pass:9, Batch:100, Cost:1.15459, Accuracy:0.75000\n",
      "Pass:10, Batch:0, Cost:1.23108, Accuracy:0.75000\n",
      "Pass:10, Batch:50, Cost:1.02553, Accuracy:0.62500\n",
      "Pass:10, Batch:100, Cost:1.14552, Accuracy:0.56250\n",
      "Pass:11, Batch:0, Cost:1.23714, Accuracy:0.62500\n",
      "Pass:11, Batch:50, Cost:1.68995, Accuracy:0.31250\n",
      "Pass:11, Batch:100, Cost:1.18272, Accuracy:0.50000\n",
      "Pass:12, Batch:0, Cost:0.92153, Accuracy:0.68750\n",
      "Pass:12, Batch:50, Cost:1.02289, Accuracy:0.62500\n",
      "Pass:12, Batch:100, Cost:0.84158, Accuracy:0.62500\n",
      "Pass:13, Batch:0, Cost:1.35656, Accuracy:0.50000\n",
      "Pass:13, Batch:50, Cost:0.78781, Accuracy:0.81250\n",
      "Pass:13, Batch:100, Cost:0.87289, Accuracy:0.75000\n",
      "Pass:14, Batch:0, Cost:0.86487, Accuracy:0.68750\n",
      "Pass:14, Batch:50, Cost:1.16826, Accuracy:0.43750\n",
      "Pass:14, Batch:100, Cost:0.86585, Accuracy:0.68750\n"
     ]
    }
   ],
   "source": [
    "##优化内存\n",
    "optimized = fluid.transpiler.memory_optimize(input_program=fluid.default_main_program(), print_log=False)\n",
    "\n",
    "##定义数据维度\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\n",
    "\n",
    "for pass_id in range(15):\n",
    "    for batch_id,data in enumerate(train_reader()):\n",
    "        train_cost,train_acc=exe.run(program = fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\n",
    "        if batch_id%50==0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretrain_model_path='models/step-1_model/'\n",
    "\n",
    "##删除旧的模型文件\n",
    "shutil.rmtree(save_pretrain_model_path,ignore_errors=True)\n",
    "##创建保存模型文件记录\n",
    "os.makedirs(save_pretrain_model_path)\n",
    "##保存参数模型\n",
    "fluid.io.save_params(executor=exe,dirname=save_pretrain_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "import paddle.dataset.flowers as flowers\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取数据\n",
    "train_reader = paddle.batch(reader.train(), batch_size=16)\n",
    "test_reader = paddle.batch(reader.val(), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义resnet，加上fc\n",
    "def resnet(input,class_dim):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "            \n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 23, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=32, filter_size=3, stride=2, act='relu', name='conv1_1')\n",
    "    conv = conv_bn_layer(input=conv, num_filters=32, filter_size=3, stride=1, act='relu', name='conv1_2')\n",
    "    conv = conv_bn_layer(input=conv, num_filters=64, filter_size=3, stride=1, act='relu', name='conv1_3')\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            if block == 2:\n",
    "                if i == 0:\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\n",
    "                else:\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\n",
    "            else:\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    output=fluid.layers.fc(input=pool,size=class_dim,act='softmax')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义输入层\n",
    "image = fluid.layers.data(name='image', shape=[3, 224, 224], dtype='float32')\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "\n",
    "##获取分类器\n",
    "model = resnet(image,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##获取训练和测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义优化方法\n",
    "optimizer=fluid.optimizer.AdamOptimizer(learning_rate=5e-4)\n",
    "opts=optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##定义一个使用GPU的执行器\n",
    "use_gpu=True\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "exe=fluid.Executor(place)\n",
    "\n",
    "##进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##经过step-1处理后的的预训练模型\n",
    "pretrained_model_path = 'models/step-1_model/'\n",
    "\n",
    "##加载经过处理的模型\n",
    "fluid.io.load_params(executor=exe, dirname=pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:1.59746, Accuracy:0.50000\n",
      "Pass:0, Batch:10, Cost:2.09788, Accuracy:0.31250\n",
      "Pass:0, Batch:20, Cost:1.61234, Accuracy:0.31250\n",
      "Pass:0, Batch:30, Cost:1.25963, Accuracy:0.56250\n",
      "Pass:0, Batch:40, Cost:1.99861, Accuracy:0.31250\n",
      "Pass:0, Batch:50, Cost:1.52093, Accuracy:0.43750\n",
      "Pass:0, Batch:60, Cost:1.83506, Accuracy:0.43750\n",
      "Pass:0, Batch:70, Cost:2.01940, Accuracy:0.50000\n",
      "Pass:0, Batch:80, Cost:1.20593, Accuracy:0.62500\n",
      "Pass:0, Batch:90, Cost:1.89012, Accuracy:0.37500\n",
      "Pass:0, Batch:100, Cost:1.62559, Accuracy:0.50000\n",
      "Test:0, Cost:2.54245, Accuracy:0.32108\n",
      "Pass:1, Batch:0, Cost:1.30175, Accuracy:0.56250\n",
      "Pass:1, Batch:10, Cost:1.55085, Accuracy:0.37500\n",
      "Pass:1, Batch:20, Cost:1.80501, Accuracy:0.37500\n",
      "Pass:1, Batch:30, Cost:2.42322, Accuracy:0.37500\n",
      "Pass:1, Batch:40, Cost:1.62112, Accuracy:0.50000\n",
      "Pass:1, Batch:50, Cost:1.49379, Accuracy:0.56250\n",
      "Pass:1, Batch:60, Cost:2.12707, Accuracy:0.31250\n",
      "Pass:1, Batch:70, Cost:1.51479, Accuracy:0.43750\n",
      "Pass:1, Batch:80, Cost:1.41728, Accuracy:0.37500\n",
      "Pass:1, Batch:90, Cost:1.55354, Accuracy:0.50000\n",
      "Pass:1, Batch:100, Cost:1.55704, Accuracy:0.37500\n",
      "Test:1, Cost:1.67868, Accuracy:0.45037\n",
      "Pass:2, Batch:0, Cost:1.83929, Accuracy:0.43750\n",
      "Pass:2, Batch:10, Cost:1.89411, Accuracy:0.43750\n",
      "Pass:2, Batch:20, Cost:1.25154, Accuracy:0.56250\n",
      "Pass:2, Batch:30, Cost:1.12986, Accuracy:0.62500\n",
      "Pass:2, Batch:40, Cost:1.28715, Accuracy:0.43750\n",
      "Pass:2, Batch:50, Cost:1.46039, Accuracy:0.56250\n",
      "Pass:2, Batch:60, Cost:1.56660, Accuracy:0.37500\n",
      "Pass:2, Batch:70, Cost:1.72513, Accuracy:0.50000\n",
      "Pass:2, Batch:80, Cost:0.79144, Accuracy:0.68750\n",
      "Pass:2, Batch:90, Cost:1.61101, Accuracy:0.25000\n",
      "Pass:2, Batch:100, Cost:1.26911, Accuracy:0.37500\n",
      "Test:2, Cost:1.81924, Accuracy:0.43382\n",
      "Pass:3, Batch:0, Cost:1.61662, Accuracy:0.50000\n",
      "Pass:3, Batch:10, Cost:1.18626, Accuracy:0.56250\n",
      "Pass:3, Batch:20, Cost:1.58670, Accuracy:0.37500\n",
      "Pass:3, Batch:30, Cost:1.61116, Accuracy:0.37500\n",
      "Pass:3, Batch:40, Cost:1.46252, Accuracy:0.56250\n",
      "Pass:3, Batch:50, Cost:0.95557, Accuracy:0.62500\n",
      "Pass:3, Batch:60, Cost:1.67436, Accuracy:0.43750\n",
      "Pass:3, Batch:70, Cost:1.00077, Accuracy:0.75000\n",
      "Pass:3, Batch:80, Cost:0.98969, Accuracy:0.62500\n",
      "Pass:3, Batch:90, Cost:1.64777, Accuracy:0.43750\n",
      "Pass:3, Batch:100, Cost:1.08343, Accuracy:0.56250\n",
      "Test:3, Cost:1.25628, Accuracy:0.59375\n",
      "Pass:4, Batch:0, Cost:1.21367, Accuracy:0.62500\n",
      "Pass:4, Batch:10, Cost:1.43413, Accuracy:0.50000\n",
      "Pass:4, Batch:20, Cost:1.86402, Accuracy:0.37500\n",
      "Pass:4, Batch:30, Cost:1.09960, Accuracy:0.56250\n",
      "Pass:4, Batch:40, Cost:0.88449, Accuracy:0.62500\n",
      "Pass:4, Batch:50, Cost:1.59482, Accuracy:0.43750\n",
      "Pass:4, Batch:60, Cost:0.98997, Accuracy:0.56250\n",
      "Pass:4, Batch:70, Cost:2.00909, Accuracy:0.43750\n",
      "Pass:4, Batch:80, Cost:0.97516, Accuracy:0.50000\n",
      "Pass:4, Batch:90, Cost:1.57698, Accuracy:0.43750\n",
      "Pass:4, Batch:100, Cost:0.59189, Accuracy:0.81250\n",
      "Test:4, Cost:0.82609, Accuracy:0.70650\n",
      "Pass:5, Batch:0, Cost:0.69073, Accuracy:0.68750\n",
      "Pass:5, Batch:10, Cost:1.10770, Accuracy:0.62500\n",
      "Pass:5, Batch:20, Cost:1.40480, Accuracy:0.43750\n",
      "Pass:5, Batch:30, Cost:0.88145, Accuracy:0.68750\n",
      "Pass:5, Batch:40, Cost:1.18393, Accuracy:0.56250\n",
      "Pass:5, Batch:50, Cost:1.99596, Accuracy:0.43750\n",
      "Pass:5, Batch:60, Cost:1.13788, Accuracy:0.56250\n",
      "Pass:5, Batch:70, Cost:1.99813, Accuracy:0.43750\n",
      "Pass:5, Batch:80, Cost:1.59868, Accuracy:0.43750\n",
      "Pass:5, Batch:90, Cost:1.61884, Accuracy:0.43750\n",
      "Pass:5, Batch:100, Cost:0.70227, Accuracy:0.62500\n",
      "Test:5, Cost:1.00064, Accuracy:0.65993\n",
      "Pass:6, Batch:0, Cost:0.63408, Accuracy:0.75000\n",
      "Pass:6, Batch:10, Cost:1.15813, Accuracy:0.56250\n",
      "Pass:6, Batch:20, Cost:1.42147, Accuracy:0.56250\n",
      "Pass:6, Batch:30, Cost:1.16247, Accuracy:0.75000\n",
      "Pass:6, Batch:40, Cost:2.41364, Accuracy:0.25000\n",
      "Pass:6, Batch:50, Cost:1.06344, Accuracy:0.56250\n",
      "Pass:6, Batch:60, Cost:0.91786, Accuracy:0.68750\n",
      "Pass:6, Batch:70, Cost:1.15077, Accuracy:0.68750\n",
      "Pass:6, Batch:80, Cost:0.75843, Accuracy:0.75000\n",
      "Pass:6, Batch:90, Cost:0.78007, Accuracy:0.62500\n",
      "Pass:6, Batch:100, Cost:1.53850, Accuracy:0.37500\n",
      "Test:6, Cost:0.77735, Accuracy:0.73468\n",
      "Pass:7, Batch:0, Cost:0.80310, Accuracy:0.56250\n",
      "Pass:7, Batch:10, Cost:0.82011, Accuracy:0.75000\n",
      "Pass:7, Batch:20, Cost:0.91465, Accuracy:0.75000\n",
      "Pass:7, Batch:30, Cost:1.47258, Accuracy:0.62500\n",
      "Pass:7, Batch:40, Cost:1.13388, Accuracy:0.43750\n",
      "Pass:7, Batch:50, Cost:1.10062, Accuracy:0.62500\n",
      "Pass:7, Batch:60, Cost:1.41127, Accuracy:0.56250\n",
      "Pass:7, Batch:70, Cost:0.79835, Accuracy:0.62500\n",
      "Pass:7, Batch:80, Cost:1.25297, Accuracy:0.56250\n",
      "Pass:7, Batch:90, Cost:1.20055, Accuracy:0.62500\n",
      "Pass:7, Batch:100, Cost:1.02110, Accuracy:0.68750\n",
      "Test:7, Cost:1.01961, Accuracy:0.67279\n",
      "Pass:8, Batch:0, Cost:1.38910, Accuracy:0.56250\n",
      "Pass:8, Batch:10, Cost:0.96755, Accuracy:0.56250\n",
      "Pass:8, Batch:20, Cost:0.73033, Accuracy:0.68750\n",
      "Pass:8, Batch:30, Cost:0.85153, Accuracy:0.68750\n",
      "Pass:8, Batch:40, Cost:0.59182, Accuracy:0.81250\n",
      "Pass:8, Batch:50, Cost:1.59194, Accuracy:0.62500\n",
      "Pass:8, Batch:60, Cost:0.90777, Accuracy:0.62500\n",
      "Pass:8, Batch:70, Cost:0.70828, Accuracy:0.68750\n",
      "Pass:8, Batch:80, Cost:0.54986, Accuracy:0.81250\n",
      "Pass:8, Batch:90, Cost:1.14367, Accuracy:0.56250\n",
      "Pass:8, Batch:100, Cost:0.57302, Accuracy:0.87500\n",
      "Test:8, Cost:1.02398, Accuracy:0.68137\n",
      "Pass:9, Batch:0, Cost:0.87414, Accuracy:0.75000\n",
      "Pass:9, Batch:10, Cost:1.22716, Accuracy:0.50000\n",
      "Pass:9, Batch:20, Cost:1.45062, Accuracy:0.50000\n",
      "Pass:9, Batch:30, Cost:1.27094, Accuracy:0.50000\n",
      "Pass:9, Batch:40, Cost:0.88913, Accuracy:0.62500\n",
      "Pass:9, Batch:50, Cost:1.41534, Accuracy:0.62500\n",
      "Pass:9, Batch:60, Cost:0.87704, Accuracy:0.62500\n",
      "Pass:9, Batch:70, Cost:0.64595, Accuracy:0.75000\n",
      "Pass:9, Batch:80, Cost:1.22910, Accuracy:0.56250\n",
      "Pass:9, Batch:90, Cost:0.87323, Accuracy:0.56250\n",
      "Pass:9, Batch:100, Cost:0.75281, Accuracy:0.68750\n",
      "Test:9, Cost:0.78879, Accuracy:0.77145\n"
     ]
    }
   ],
   "source": [
    "##定义数据维度\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\n",
    "for pass_id in range(10):\n",
    "    ##训练\n",
    "    for batch_id,data in enumerate(train_reader()):\n",
    "        train_cost,train_acc=exe.run(program=fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\n",
    "        if batch_id%10==0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "    ##测试\n",
    "    test_accs=[]\n",
    "    test_costs=[]\n",
    "    for batch_id,data in enumerate(test_reader()):\n",
    "        test_cost,test_acc=exe.run(program=test_program,feed=feeder.feed(data), fetch_list=[avg_cost,acc])\n",
    "        test_accs.append(test_acc[0])\n",
    "        test_costs.append(test_cost[0])\n",
    "    test_cost = (sum(test_costs) / len(test_costs))\n",
    "    test_acc = (sum(test_accs) / len(test_accs))\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['save_infer_model/scale_0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##保存预测模型\n",
    "save_path = 'models/step_2_model/'\n",
    "\n",
    "##删除旧的模型文件\n",
    "shutil.rmtree(save_path, ignore_errors=True)\n",
    "##创建保持模型文件目录\n",
    "os.makedirs(save_path)\n",
    "##保存预测模型\n",
    "fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[model], executor=exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在生成模型文件（model）后，运行该cell\n",
    "# 在生成CSV文件过程中，有任何问题可咨询助教\n",
    "# 助教将辅助大家生成CSV文件\n",
    "\n",
    "\n",
    "# 注意！！！\n",
    "# 除变量\"SAVE_DIRNAME\"外，请不要私自改动其他代码。有问题请联系助教\n",
    "#########################################################################\n",
    "\"\"\"注意！！！\n",
    "\n",
    "请将变量\"SAVE_DIRNAME\"的值修改为模型文件（model）的路径。如：\n",
    "SAVE_DIRNAME = './models/step_2_model'\n",
    "\"\"\"\n",
    "# 请对该行代码出修改：\n",
    "SAVE_DIRNAME = './models/step_2_model'  # 保存好的 inference model 的路径\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "运行generate_CSV_file_with_infer.py\n",
    "脚本文件generate_CSV_file_with_infer.py实现生成CSV文件的功能\n",
    "脚本文件将读取训练好的模型（model）和测试集数据（test）\n",
    "并将模型对测试集数据的预测结果保存为CSV文件\n",
    "\"\"\"\n",
    "\n",
    "# coding:utf-8\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "# 根据竞赛规则更改 TopK 的值。本次竞赛只看 top 1 的值\n",
    "TOP_K = 1\n",
    "\n",
    "SAVE_DIRNAME = './models/step_2_model'  # 保存好的 inference model 的路径\n",
    "\n",
    "DATA_DIM = 224\n",
    "\n",
    "use_cuda = True\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "# 下面行代码根据自己保存时的写法匹配\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model( SAVE_DIRNAME, exe,\n",
    "                # model_filename='model',\n",
    "                # params_filename='params'\n",
    "                # model_filename = 'fc_0.w_0',\n",
    "                # params_filename = 'params'\n",
    "                )\n",
    "\n",
    "\n",
    "def real_infer_one_img(im):\n",
    "    infer_result = exe.run(\n",
    "        inference_program,\n",
    "        feed={feed_target_names[0]: im},\n",
    "        fetch_list=fetch_targets)\n",
    "\n",
    "    # print(infer_result)\n",
    "    # 打印预测结果\n",
    "    mini_batch_result = np.argsort(infer_result)  # 找出可能性最大的列标，升序排列\n",
    "    # print(mini_batch_result.shape)\n",
    "    mini_batch_result = mini_batch_result[0][:, -TOP_K:]  # 把这些列标拿出来\n",
    "    # print('预测结果：%s' % mini_batch_result)\n",
    "    # 打印真实结果\n",
    "    # label = np.array(test_y)  # 转化为 label\n",
    "    # print('真实结果：%s' % label)\n",
    "    mini_batch_result = mini_batch_result.flatten() #拉平了，只吐出一个 array\n",
    "    mini_batch_result = mini_batch_result[::-1] #逆序\n",
    "    return mini_batch_result\n",
    "\n",
    "\n",
    "def resize_short(img, target_size):\n",
    "    percent = float(target_size) / min(img.size[0], img.size[1])\n",
    "    resized_width = int(round(img.size[0] * percent))\n",
    "    resized_height = int(round(img.size[1] * percent))\n",
    "    img = img.resize((resized_width, resized_height), Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_image(img, target_size, center):\n",
    "    width, height = img.size\n",
    "    size = target_size\n",
    "    if center == True:\n",
    "        w_start = (width - size) / 2\n",
    "        h_start = (height - size) / 2\n",
    "    else:\n",
    "        w_start = np.random.randint(0, width - size + 1)\n",
    "        h_start = np.random.randint(0, height - size + 1)\n",
    "    w_end = w_start + size\n",
    "    h_end = h_start + size\n",
    "    img = img.crop((w_start, h_start, w_end, h_end))\n",
    "    return img\n",
    "\n",
    "img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = resize_short(img, target_size=256)\n",
    "    img = crop_image(img, target_size=DATA_DIM, center=True)\n",
    "\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    img = np.array(img).astype(np.float32).transpose((2, 0, 1)) / 255\n",
    "    img -= img_mean\n",
    "    img /= img_std\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def convert_list(my_list):\n",
    "    my_list = list(my_list)\n",
    "    my_list = map(lambda x:str(x), my_list)\n",
    "    # print('_'.join(my_list))\n",
    "    return '_'.join(my_list)\n",
    "\n",
    "\n",
    "def infer(file_path):\n",
    "    im = process_image(file_path)\n",
    "    result = real_infer_one_img(im)\n",
    "    result = convert_list(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createCSVFile(cat_12_test_path):\n",
    "    lines = []\n",
    "\n",
    "    # 获取所有的文件名\n",
    "    img_paths = os.listdir(cat_12_test_path)\n",
    "    for file_name in img_paths:\n",
    "        file_name = file_name\n",
    "        file_abs_path = os.path.join(cat_12_test_path, file_name)\n",
    "        result_classes = infer(file_abs_path)\n",
    "\n",
    "        file_predict_classes = result_classes\n",
    "\n",
    "        line = '%s,%s\\n'%(file_name, file_predict_classes)\n",
    "        lines.append(line)\n",
    "\n",
    "    with open('csv_file_path.csv', 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "abs_path = r'./cat_12/cat_12_test' # cat_12_test 文件夹的真实路径\n",
    "createCSVFile(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow35",
   "language": "python",
   "name": "tensorflow35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
