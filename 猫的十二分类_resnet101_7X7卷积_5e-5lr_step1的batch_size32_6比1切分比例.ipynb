{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data7983\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained\r\n"
     ]
    }
   ],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip data/data7983/cat_12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_12/train_split_list.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function paddle.reader.decorator.xmap_readers.<locals>.xreader()>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import reader\n",
    "reader.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-17 11:42:16--  http://paddle-imagenet-models-name.bj.bcebos.com/ResNet101_pretrained.tar\n",
      "Resolving paddle-imagenet-models-name.bj.bcebos.com (paddle-imagenet-models-name.bj.bcebos.com)... 220.181.33.48, 220.181.33.43, 220.181.33.44, ...\n",
      "Connecting to paddle-imagenet-models-name.bj.bcebos.com (paddle-imagenet-models-name.bj.bcebos.com)|220.181.33.48|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 179148800 (171M) [application/x-tar]\n",
      "Saving to: ‘ResNet101_pretrained.tar’\n",
      "\n",
      "ResNet101_pretraine 100%[===================>] 170.85M  20.4MB/s    in 6.0s    \n",
      "\n",
      "2019-06-17 11:42:23 (28.7 MB/s) - ‘ResNet101_pretrained.tar’ saved [179148800/179148800]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_vd_pretrained.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!tar -xvf ResNet50_vd_pretrained.tar -C work/pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "import reader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##生成test.txt\n",
    "#filepath='cat_12/cat_12_test'\n",
    "#pathlist=os.listdir(filepath)\n",
    "#print(pathlist)\n",
    "#with open('cat_12/test_list.txt','w+') as f:\n",
    "    #for file_name in pathlist:\n",
    "        #f.write(file_name+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    180\n",
      "9     180\n",
      "7     180\n",
      "5     180\n",
      "3     180\n",
      "1     180\n",
      "10    180\n",
      "8     180\n",
      "6     180\n",
      "4     180\n",
      "2     180\n",
      "0     180\n",
      "Name: 1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_table('cat_12/train_list.txt',header=None)\n",
    "print(a[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##处理数据集，将原有训练集按二八比例分割\n",
    "with open('cat_12/train_list.txt','r') as f:\n",
    "    with open('cat_12/train_split_list.txt','w+') as train:\n",
    "        lines=f.readlines()\n",
    "    with open('cat_12/train_split_list.txt','w+') as train:\n",
    "        for i in range(0,2160,180):\n",
    "            for line in lines[i:i+160]:\n",
    "                train.write(line)\n",
    "    with open('cat_12/val_split_list.txt','w+') as val:\n",
    "        for i in range(0,2160,180):\n",
    "            for line in lines[i+160:i+180]:\n",
    "                val.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    160\n",
      "10    160\n",
      "9     160\n",
      "8     160\n",
      "7     160\n",
      "6     160\n",
      "5     160\n",
      "4     160\n",
      "3     160\n",
      "2     160\n",
      "1     160\n",
      "0     160\n",
      "Name: 1, dtype: int64\n",
      "11    20\n",
      "10    20\n",
      "9     20\n",
      "8     20\n",
      "7     20\n",
      "6     20\n",
      "5     20\n",
      "4     20\n",
      "3     20\n",
      "2     20\n",
      "1     20\n",
      "0     20\n",
      "Name: 1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_table('cat_12/train_split_list.txt',header=None)\n",
    "print(train[1].value_counts())\n",
    "val=pd.read_table('cat_12/val_split_list.txt',header=None)\n",
    "print(val[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##获取猫数据\n",
    "train_reader = paddle.batch(reader.train(), batch_size=32)\n",
    "test_reader = paddle.batch(reader.val(), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##定义残差网络\n",
    "def resnet(input):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "            \n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 23, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            if block == 2:\n",
    "                if i == 0:\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\n",
    "                else:\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\n",
    "            else:\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    return pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##定义输入层\n",
    "image=fluid.layers.data(name='image',shape=[3,224,224],dtype='float32')\n",
    "label=fluid.layers.data(name='label',shape=[1],dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##停止梯度下降\n",
    "pool=resnet(image)\n",
    "pool.stop_gradient=True\n",
    "\n",
    "##创建主程序\n",
    "base_model_program=fluid.default_main_program().clone()\n",
    "model=fluid.layers.fc(input=pool,size=12,act='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##定义损失函数和准确率函数\n",
    "cost=fluid.layers.cross_entropy(input=model,label=label)\n",
    "avg_cost=fluid.layers.mean(cost)\n",
    "acc=fluid.layers.accuracy(input=model,label=label)\n",
    "\n",
    "##定义优化方法\n",
    "optimizer=fluid.optimizer.AdamOptimizer(learning_rate=1e-4)\n",
    "opts=optimizer.minimize(avg_cost)\n",
    "\n",
    "##定义训练场所\n",
    "use_gpu=True\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "exe=fluid.Executor(place)\n",
    "\n",
    "##进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##预训练模型路径\n",
    "src_pretrain_model_path='work/pretrained/ResNet101_pretrained'\n",
    "\n",
    "##判断模型文件是否存在\n",
    "def if_exit(var):\n",
    "    path=os.path.join(src_pretrain_model_path,var.name)\n",
    "    exist=os.path.exists(path)\n",
    "    return exist\n",
    "\n",
    "##加载模型文件，且只加载存在模型的模型文件\n",
    "fluid.io.load_vars(executor=exe,dirname=src_pretrain_model_path,predicate=if_exit,main_program=base_model_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "memory_optimize is deprecated. Use CompiledProgram and Executor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.79346, Accuracy:0.06250\n",
      "Pass:0, Batch:50, Cost:2.28637, Accuracy:0.25000\n",
      "Pass:1, Batch:0, Cost:2.10973, Accuracy:0.37500\n",
      "Pass:1, Batch:50, Cost:1.87521, Accuracy:0.53125\n",
      "Pass:2, Batch:0, Cost:1.91897, Accuracy:0.37500\n",
      "Pass:2, Batch:50, Cost:1.63321, Accuracy:0.62500\n",
      "Pass:3, Batch:0, Cost:1.66540, Accuracy:0.43750\n",
      "Pass:3, Batch:50, Cost:1.50399, Accuracy:0.59375\n",
      "Pass:4, Batch:0, Cost:1.43258, Accuracy:0.65625\n",
      "Pass:4, Batch:50, Cost:1.36772, Accuracy:0.59375\n",
      "Pass:5, Batch:0, Cost:1.30980, Accuracy:0.53125\n",
      "Pass:5, Batch:50, Cost:1.27056, Accuracy:0.65625\n",
      "Pass:6, Batch:0, Cost:1.21677, Accuracy:0.71875\n",
      "Pass:6, Batch:50, Cost:1.12915, Accuracy:0.75000\n",
      "Pass:7, Batch:0, Cost:1.33978, Accuracy:0.68750\n",
      "Pass:7, Batch:50, Cost:0.88163, Accuracy:0.87500\n",
      "Pass:8, Batch:0, Cost:1.08108, Accuracy:0.71875\n",
      "Pass:8, Batch:50, Cost:0.90259, Accuracy:0.78125\n",
      "Pass:9, Batch:0, Cost:0.99063, Accuracy:0.68750\n",
      "Pass:9, Batch:50, Cost:1.05527, Accuracy:0.75000\n",
      "Pass:10, Batch:0, Cost:0.84140, Accuracy:0.84375\n",
      "Pass:10, Batch:50, Cost:0.82135, Accuracy:0.84375\n",
      "Pass:11, Batch:0, Cost:0.90855, Accuracy:0.78125\n",
      "Pass:11, Batch:50, Cost:0.76524, Accuracy:0.81250\n",
      "Pass:12, Batch:0, Cost:1.06949, Accuracy:0.71875\n",
      "Pass:12, Batch:50, Cost:0.73151, Accuracy:0.84375\n",
      "Pass:13, Batch:0, Cost:0.87211, Accuracy:0.87500\n",
      "Pass:13, Batch:50, Cost:0.66733, Accuracy:0.87500\n",
      "Pass:14, Batch:0, Cost:0.85069, Accuracy:0.75000\n",
      "Pass:14, Batch:50, Cost:1.10067, Accuracy:0.68750\n"
     ]
    }
   ],
   "source": [
    "##优化内存\n",
    "optimized = fluid.transpiler.memory_optimize(input_program=fluid.default_main_program(), print_log=False)\n",
    "\n",
    "##定义数据维度\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\n",
    "\n",
    "for pass_id in range(15):\n",
    "    for batch_id,data in enumerate(train_reader()):\n",
    "        train_cost,train_acc=exe.run(program = fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\n",
    "        if batch_id%50==0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_pretrain_model_path='models/step-1_model/'\n",
    "\n",
    "##删除旧的模型文件\n",
    "shutil.rmtree(save_pretrain_model_path,ignore_errors=True)\n",
    "##创建保存模型文件记录\n",
    "os.makedirs(save_pretrain_model_path)\n",
    "##保存参数模型\n",
    "fluid.io.save_params(executor=exe,dirname=save_pretrain_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import paddle as paddle\n",
    "import paddle.dataset.flowers as flowers\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##获取数据\n",
    "train_reader = paddle.batch(reader.train(), batch_size=16)\n",
    "test_reader = paddle.batch(reader.val(), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##定义resnet，加上fc\n",
    "def resnet(input,class_dim):\n",
    "    def conv_bn_layer(input, num_filters, filter_size, stride=1, groups=1, act=None, name=None):\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=(filter_size - 1) // 2,\n",
    "                                   groups=groups,\n",
    "                                   act=None,\n",
    "                                   param_attr=ParamAttr(name=name + \"_weights\"),\n",
    "                                   bias_attr=False,\n",
    "                                   name=name + '.conv2d.output.1')\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        return fluid.layers.batch_norm(input=conv,\n",
    "                                       act=act,\n",
    "                                       name=bn_name + '.output.1',\n",
    "                                       param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "                                       bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "                                       moving_mean_name=bn_name + '_mean',\n",
    "                                       moving_variance_name=bn_name + '_variance', )\n",
    "\n",
    "    def shortcut(input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            return conv_bn_layer(input, ch_out, 1, stride, name=name)\n",
    "        else:\n",
    "            return input\n",
    "            \n",
    "    def bottleneck_block(input, num_filters, stride, name):\n",
    "        conv0 = conv_bn_layer(input=input,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=1,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2a\")\n",
    "        conv1 = conv_bn_layer(input=conv0,\n",
    "                              num_filters=num_filters,\n",
    "                              filter_size=3,\n",
    "                              stride=stride,\n",
    "                              act='relu',\n",
    "                              name=name + \"_branch2b\")\n",
    "        conv2 = conv_bn_layer(input=conv1,\n",
    "                              num_filters=num_filters * 4,\n",
    "                              filter_size=1,\n",
    "                              act=None,\n",
    "                              name=name + \"_branch2c\")\n",
    "\n",
    "        short = shortcut(input, num_filters * 4, stride, name=name + \"_branch1\")\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu', name=name + \".add.output.5\")\n",
    "\n",
    "    depth = [3, 4, 23, 3]\n",
    "    num_filters = [64, 128, 256, 512]\n",
    "\n",
    "    conv = conv_bn_layer(input=input, num_filters=64, filter_size=7, stride=2, act='relu', name=\"conv1\")\n",
    "    conv = fluid.layers.pool2d(input=conv, pool_size=3, pool_stride=2, pool_padding=1, pool_type='max')\n",
    "\n",
    "    for block in range(len(depth)):\n",
    "        for i in range(depth[block]):\n",
    "            if block == 2:\n",
    "                if i == 0:\n",
    "                    conv_name=\"res\"+str(block+2)+\"a\"\n",
    "                else:\n",
    "                    conv_name=\"res\"+str(block+2)+\"b\"+str(i)\n",
    "            else:\n",
    "                    conv_name=\"res\"+str(block+2)+chr(97+i)\n",
    "            conv = bottleneck_block(input=conv,\n",
    "                                    num_filters=num_filters[block],\n",
    "                                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                                    name=conv_name)\n",
    "\n",
    "    pool = fluid.layers.pool2d(input=conv, pool_size=7, pool_type='avg', global_pooling=True)\n",
    "    output=fluid.layers.fc(input=pool,size=class_dim,act='softmax')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##定义输入层\n",
    "image = fluid.layers.data(name='image', shape=[3, 224, 224], dtype='float32')\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "\n",
    "##获取分类器\n",
    "model = resnet(image,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##获取训练和测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##定义优化方法\n",
    "optimizer=fluid.optimizer.AdamOptimizer(learning_rate=1e-5)\n",
    "opts=optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##定义一个使用GPU的执行器\n",
    "use_gpu=True\n",
    "place=fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "exe=fluid.Executor(place)\n",
    "\n",
    "##进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##经过step-1处理后的的预训练模型\n",
    "pretrained_model_path = 'models/step-1_model/'\n",
    "\n",
    "##加载经过处理的模型\n",
    "fluid.io.load_params(executor=exe, dirname=pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:0.76633, Accuracy:0.68750\n",
      "Pass:0, Batch:10, Cost:0.68326, Accuracy:0.81250\n",
      "Pass:0, Batch:20, Cost:0.72604, Accuracy:0.81250\n",
      "Pass:0, Batch:30, Cost:0.84618, Accuracy:0.81250\n",
      "Pass:0, Batch:40, Cost:0.43655, Accuracy:0.93750\n",
      "Pass:0, Batch:50, Cost:0.74160, Accuracy:0.75000\n",
      "Pass:0, Batch:60, Cost:0.93149, Accuracy:0.62500\n",
      "Pass:0, Batch:70, Cost:0.87208, Accuracy:0.75000\n",
      "Pass:0, Batch:80, Cost:0.64400, Accuracy:0.81250\n",
      "Pass:0, Batch:90, Cost:0.49729, Accuracy:0.81250\n",
      "Pass:0, Batch:100, Cost:0.56479, Accuracy:0.81250\n",
      "Pass:0, Batch:110, Cost:0.89612, Accuracy:0.56250\n",
      "Test:0, Cost:0.30351, Accuracy:0.90417\n",
      "Pass:1, Batch:0, Cost:0.40023, Accuracy:0.87500\n",
      "Pass:1, Batch:10, Cost:0.65602, Accuracy:0.87500\n",
      "Pass:1, Batch:20, Cost:0.41457, Accuracy:1.00000\n",
      "Pass:1, Batch:30, Cost:0.69979, Accuracy:0.75000\n",
      "Pass:1, Batch:40, Cost:0.43713, Accuracy:0.81250\n",
      "Pass:1, Batch:50, Cost:0.74879, Accuracy:0.68750\n",
      "Pass:1, Batch:60, Cost:0.45472, Accuracy:0.93750\n",
      "Pass:1, Batch:70, Cost:0.45300, Accuracy:0.87500\n",
      "Pass:1, Batch:80, Cost:0.27701, Accuracy:0.93750\n",
      "Pass:1, Batch:90, Cost:0.50417, Accuracy:0.75000\n",
      "Pass:1, Batch:100, Cost:0.46106, Accuracy:0.87500\n",
      "Pass:1, Batch:110, Cost:0.72361, Accuracy:0.75000\n",
      "Test:1, Cost:0.24941, Accuracy:0.93333\n",
      "Pass:2, Batch:0, Cost:0.32357, Accuracy:0.93750\n",
      "Pass:2, Batch:10, Cost:0.47847, Accuracy:0.87500\n",
      "Pass:2, Batch:20, Cost:0.55021, Accuracy:0.81250\n",
      "Pass:2, Batch:30, Cost:0.31278, Accuracy:0.87500\n",
      "Pass:2, Batch:40, Cost:0.33812, Accuracy:0.87500\n",
      "Pass:2, Batch:50, Cost:0.54459, Accuracy:0.87500\n",
      "Pass:2, Batch:60, Cost:0.42241, Accuracy:0.87500\n",
      "Pass:2, Batch:70, Cost:0.59350, Accuracy:0.87500\n",
      "Pass:2, Batch:80, Cost:0.35590, Accuracy:0.81250\n",
      "Pass:2, Batch:90, Cost:0.27545, Accuracy:0.87500\n",
      "Pass:2, Batch:100, Cost:0.32249, Accuracy:0.87500\n",
      "Pass:2, Batch:110, Cost:0.25479, Accuracy:0.87500\n",
      "Test:2, Cost:0.24862, Accuracy:0.94167\n",
      "Pass:3, Batch:0, Cost:0.38323, Accuracy:0.87500\n",
      "Pass:3, Batch:10, Cost:0.25570, Accuracy:0.93750\n",
      "Pass:3, Batch:20, Cost:0.23662, Accuracy:0.93750\n",
      "Pass:3, Batch:30, Cost:0.11288, Accuracy:1.00000\n",
      "Pass:3, Batch:40, Cost:0.37477, Accuracy:0.93750\n",
      "Pass:3, Batch:50, Cost:0.43662, Accuracy:0.87500\n",
      "Pass:3, Batch:60, Cost:0.45231, Accuracy:0.81250\n",
      "Pass:3, Batch:70, Cost:0.80360, Accuracy:0.75000\n",
      "Pass:3, Batch:80, Cost:0.07312, Accuracy:1.00000\n",
      "Pass:3, Batch:90, Cost:0.50123, Accuracy:0.87500\n",
      "Pass:3, Batch:100, Cost:0.07488, Accuracy:1.00000\n",
      "Pass:3, Batch:110, Cost:0.35156, Accuracy:0.87500\n",
      "Test:3, Cost:0.21829, Accuracy:0.95000\n",
      "Pass:4, Batch:0, Cost:0.36297, Accuracy:0.93750\n",
      "Pass:4, Batch:10, Cost:0.61861, Accuracy:0.81250\n",
      "Pass:4, Batch:20, Cost:0.42017, Accuracy:0.81250\n",
      "Pass:4, Batch:30, Cost:0.17971, Accuracy:0.93750\n",
      "Pass:4, Batch:40, Cost:0.58283, Accuracy:0.81250\n",
      "Pass:4, Batch:50, Cost:0.25528, Accuracy:0.93750\n",
      "Pass:4, Batch:60, Cost:0.36698, Accuracy:0.93750\n",
      "Pass:4, Batch:70, Cost:0.21160, Accuracy:0.93750\n",
      "Pass:4, Batch:80, Cost:0.30392, Accuracy:0.87500\n",
      "Pass:4, Batch:90, Cost:0.12581, Accuracy:1.00000\n",
      "Pass:4, Batch:100, Cost:0.21485, Accuracy:0.93750\n",
      "Pass:4, Batch:110, Cost:0.30395, Accuracy:0.87500\n",
      "Test:4, Cost:0.18974, Accuracy:0.95000\n",
      "Pass:5, Batch:0, Cost:0.40892, Accuracy:0.93750\n",
      "Pass:5, Batch:10, Cost:0.25068, Accuracy:0.93750\n",
      "Pass:5, Batch:20, Cost:0.31846, Accuracy:0.87500\n",
      "Pass:5, Batch:30, Cost:0.55141, Accuracy:0.81250\n",
      "Pass:5, Batch:40, Cost:0.33087, Accuracy:0.87500\n",
      "Pass:5, Batch:50, Cost:0.51320, Accuracy:0.75000\n",
      "Pass:5, Batch:60, Cost:0.15861, Accuracy:0.93750\n",
      "Pass:5, Batch:70, Cost:0.17459, Accuracy:0.93750\n",
      "Pass:5, Batch:80, Cost:0.20597, Accuracy:0.93750\n",
      "Pass:5, Batch:90, Cost:0.17012, Accuracy:0.93750\n",
      "Pass:5, Batch:100, Cost:0.26725, Accuracy:0.87500\n",
      "Pass:5, Batch:110, Cost:0.33722, Accuracy:0.87500\n",
      "Test:5, Cost:0.20165, Accuracy:0.94583\n",
      "Pass:6, Batch:0, Cost:0.14849, Accuracy:0.93750\n",
      "Pass:6, Batch:10, Cost:0.54202, Accuracy:0.81250\n",
      "Pass:6, Batch:20, Cost:0.26599, Accuracy:0.81250\n",
      "Pass:6, Batch:30, Cost:0.44333, Accuracy:0.81250\n",
      "Pass:6, Batch:40, Cost:0.12984, Accuracy:0.93750\n",
      "Pass:6, Batch:50, Cost:0.37698, Accuracy:0.93750\n",
      "Pass:6, Batch:60, Cost:0.05070, Accuracy:1.00000\n",
      "Pass:6, Batch:70, Cost:0.43882, Accuracy:0.81250\n",
      "Pass:6, Batch:80, Cost:0.40586, Accuracy:0.75000\n",
      "Pass:6, Batch:90, Cost:0.24809, Accuracy:0.87500\n",
      "Pass:6, Batch:100, Cost:0.37301, Accuracy:0.87500\n",
      "Pass:6, Batch:110, Cost:0.22997, Accuracy:0.93750\n",
      "Test:6, Cost:0.21636, Accuracy:0.93333\n",
      "Pass:7, Batch:0, Cost:0.36325, Accuracy:0.93750\n",
      "Pass:7, Batch:10, Cost:0.29392, Accuracy:0.93750\n",
      "Pass:7, Batch:20, Cost:0.20430, Accuracy:0.87500\n",
      "Pass:7, Batch:30, Cost:0.26973, Accuracy:0.81250\n",
      "Pass:7, Batch:40, Cost:0.23348, Accuracy:0.93750\n",
      "Pass:7, Batch:50, Cost:0.19536, Accuracy:0.93750\n",
      "Pass:7, Batch:60, Cost:0.12357, Accuracy:0.93750\n",
      "Pass:7, Batch:70, Cost:0.16370, Accuracy:0.93750\n",
      "Pass:7, Batch:80, Cost:0.09199, Accuracy:1.00000\n",
      "Pass:7, Batch:90, Cost:0.13228, Accuracy:0.93750\n",
      "Pass:7, Batch:100, Cost:0.12392, Accuracy:1.00000\n",
      "Pass:7, Batch:110, Cost:0.23020, Accuracy:0.93750\n",
      "Test:7, Cost:0.42032, Accuracy:0.90833\n",
      "Pass:8, Batch:0, Cost:0.36194, Accuracy:0.87500\n",
      "Pass:8, Batch:10, Cost:0.24260, Accuracy:0.93750\n",
      "Pass:8, Batch:20, Cost:0.21064, Accuracy:0.93750\n",
      "Pass:8, Batch:30, Cost:0.20070, Accuracy:0.93750\n",
      "Pass:8, Batch:40, Cost:0.39182, Accuracy:0.81250\n",
      "Pass:8, Batch:50, Cost:0.16306, Accuracy:1.00000\n",
      "Pass:8, Batch:60, Cost:0.11816, Accuracy:1.00000\n",
      "Pass:8, Batch:70, Cost:0.33613, Accuracy:0.81250\n",
      "Pass:8, Batch:80, Cost:0.31362, Accuracy:0.87500\n",
      "Pass:8, Batch:90, Cost:0.37167, Accuracy:0.87500\n",
      "Pass:8, Batch:100, Cost:0.07320, Accuracy:1.00000\n",
      "Pass:8, Batch:110, Cost:0.08403, Accuracy:1.00000\n",
      "Test:8, Cost:0.44019, Accuracy:0.93333\n",
      "Pass:9, Batch:0, Cost:0.19151, Accuracy:1.00000\n",
      "Pass:9, Batch:10, Cost:0.12354, Accuracy:0.93750\n",
      "Pass:9, Batch:20, Cost:0.38362, Accuracy:0.93750\n",
      "Pass:9, Batch:30, Cost:0.59800, Accuracy:0.87500\n",
      "Pass:9, Batch:40, Cost:0.24742, Accuracy:0.87500\n",
      "Pass:9, Batch:50, Cost:0.20591, Accuracy:0.93750\n",
      "Pass:9, Batch:60, Cost:0.35750, Accuracy:0.93750\n",
      "Pass:9, Batch:70, Cost:0.14164, Accuracy:0.93750\n",
      "Pass:9, Batch:80, Cost:0.27970, Accuracy:0.87500\n",
      "Pass:9, Batch:90, Cost:0.26864, Accuracy:0.93750\n",
      "Pass:9, Batch:100, Cost:0.34002, Accuracy:0.81250\n",
      "Pass:9, Batch:110, Cost:0.26205, Accuracy:0.87500\n",
      "Test:9, Cost:0.17093, Accuracy:0.95000\n"
     ]
    }
   ],
   "source": [
    "##定义数据维度\n",
    "feeder=fluid.DataFeeder(place=place,feed_list=[image,label])\n",
    "for pass_id in range(10):\n",
    "    ##训练\n",
    "    for batch_id,data in enumerate(train_reader()):\n",
    "        train_cost,train_acc=exe.run(program=fluid.default_main_program(),feed=feeder.feed(data),fetch_list=[avg_cost,acc])\n",
    "        if batch_id%10==0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "    ##测试\n",
    "    test_accs=[]\n",
    "    test_costs=[]\n",
    "    for batch_id,data in enumerate(test_reader()):\n",
    "        test_cost,test_acc=exe.run(program=test_program,feed=feeder.feed(data), fetch_list=[avg_cost,acc])\n",
    "        test_accs.append(test_acc[0])\n",
    "        test_costs.append(test_cost[0])\n",
    "    test_cost = (sum(test_costs) / len(test_costs))\n",
    "    test_acc = (sum(test_accs) / len(test_accs))\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['save_infer_model/scale_0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##保存预测模型\n",
    "save_path = 'models/step_2_model/'\n",
    "\n",
    "##删除旧的模型文件\n",
    "shutil.rmtree(save_path, ignore_errors=True)\n",
    "##创建保持模型文件目录\n",
    "os.makedirs(save_path)\n",
    "##保存预测模型\n",
    "fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[model], executor=exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAVE_DIRNAME = './models/step_2_model'  # 保存好的 inference model 的路径\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "运行generate_CSV_file_with_infer.py\n",
    "脚本文件generate_CSV_file_with_infer.py实现生成CSV文件的功能\n",
    "脚本文件将读取训练好的模型（model）和测试集数据（test）\n",
    "并将模型对测试集数据的预测结果保存为CSV文件\n",
    "\"\"\"\n",
    "\n",
    "# coding:utf-8\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "# 根据竞赛规则更改 TopK 的值。本次竞赛只看 top 1 的值\n",
    "TOP_K = 1\n",
    "\n",
    "SAVE_DIRNAME = './models/step_2_model'  # 保存好的 inference model 的路径\n",
    "\n",
    "DATA_DIM = 224\n",
    "\n",
    "use_cuda = True\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "# 下面行代码根据自己保存时的写法匹配\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model( SAVE_DIRNAME, exe,\n",
    "                # model_filename='model',\n",
    "                # params_filename='params'\n",
    "                # model_filename = 'fc_0.w_0',\n",
    "                # params_filename = 'params'\n",
    "                )\n",
    "\n",
    "\n",
    "def real_infer_one_img(im):\n",
    "    infer_result = exe.run(\n",
    "        inference_program,\n",
    "        feed={feed_target_names[0]: im},\n",
    "        fetch_list=fetch_targets)\n",
    "\n",
    "    # print(infer_result)\n",
    "    # 打印预测结果\n",
    "    mini_batch_result = np.argsort(infer_result)  # 找出可能性最大的列标，升序排列\n",
    "    # print(mini_batch_result.shape)\n",
    "    mini_batch_result = mini_batch_result[0][:, -TOP_K:]  # 把这些列标拿出来\n",
    "    # print('预测结果：%s' % mini_batch_result)\n",
    "    # 打印真实结果\n",
    "    # label = np.array(test_y)  # 转化为 label\n",
    "    # print('真实结果：%s' % label)\n",
    "    mini_batch_result = mini_batch_result.flatten() #拉平了，只吐出一个 array\n",
    "    mini_batch_result = mini_batch_result[::-1] #逆序\n",
    "    return mini_batch_result\n",
    "\n",
    "\n",
    "def resize_short(img, target_size):\n",
    "    percent = float(target_size) / min(img.size[0], img.size[1])\n",
    "    resized_width = int(round(img.size[0] * percent))\n",
    "    resized_height = int(round(img.size[1] * percent))\n",
    "    img = img.resize((resized_width, resized_height), Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_image(img, target_size, center):\n",
    "    width, height = img.size\n",
    "    size = target_size\n",
    "    if center == True:\n",
    "        w_start = (width - size) / 2\n",
    "        h_start = (height - size) / 2\n",
    "    else:\n",
    "        w_start = np.random.randint(0, width - size + 1)\n",
    "        h_start = np.random.randint(0, height - size + 1)\n",
    "    w_end = w_start + size\n",
    "    h_end = h_start + size\n",
    "    img = img.crop((w_start, h_start, w_end, h_end))\n",
    "    return img\n",
    "\n",
    "img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = resize_short(img, target_size=256)\n",
    "    img = crop_image(img, target_size=DATA_DIM, center=True)\n",
    "\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    img = np.array(img).astype(np.float32).transpose((2, 0, 1)) / 255\n",
    "    img -= img_mean\n",
    "    img /= img_std\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def convert_list(my_list):\n",
    "    my_list = list(my_list)\n",
    "    my_list = map(lambda x:str(x), my_list)\n",
    "    # print('_'.join(my_list))\n",
    "    return '_'.join(my_list)\n",
    "\n",
    "\n",
    "def infer(file_path):\n",
    "    im = process_image(file_path)\n",
    "    result = real_infer_one_img(im)\n",
    "    result = convert_list(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createCSVFile(cat_12_test_path):\n",
    "    lines = []\n",
    "\n",
    "    # 获取所有的文件名\n",
    "    img_paths = os.listdir(cat_12_test_path)\n",
    "    for file_name in img_paths:\n",
    "        file_name = file_name\n",
    "        file_abs_path = os.path.join(cat_12_test_path, file_name)\n",
    "        result_classes = infer(file_abs_path)\n",
    "\n",
    "        file_predict_classes = result_classes\n",
    "\n",
    "        line = '%s,%s\\n'%(file_name, file_predict_classes)\n",
    "        lines.append(line)\n",
    "\n",
    "    with open('csv_file_path.csv', 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "abs_path = r'./cat_12/cat_12_test' # cat_12_test 文件夹的真实路径\n",
    "createCSVFile(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.4.1 (Python 3.6)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
